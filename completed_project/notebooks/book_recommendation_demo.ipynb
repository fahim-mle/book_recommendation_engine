{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Book Recommendation Engine Demo\n",
        "\n",
        "This notebook demonstrates the book recommendation engine for Australian school textbooks.\n",
        "\n",
        "## Overview\n",
        "\n",
        "1. Load the dataset\n",
        "2. Explore the data\n",
        "3. Process and prepare features\n",
        "4. Train the recommendation model\n",
        "5. Generate and evaluate recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path('..').resolve()\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "# Import project modules\n",
        "from src.data_processing import TextProcessor\n",
        "from src.recommender import ContentBasedRecommender\n",
        "from src.evaluation import ModelEvaluator\n",
        "\n",
        "# Set plot style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"viridis\")\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "# For this demo, we'll use the sample data from the previous related works\n",
        "try:\n",
        "    # Try to load the augmented data first\n",
        "    data_path = project_root / 'data' / 'augmented_data.csv'\n",
        "    if not data_path.exists():\n",
        "        # If not available, use the sample data from previous related works\n",
        "        data_path = project_root.parent / 'previous_related_works' / 'A1_Data_V2.csv'\n",
        "    \n",
        "    df = pd.read_csv(data_path)\n",
        "    print(f\"Loaded data from {data_path}\")\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Could not find the dataset. Please run data collection first.\")\n",
        "    df = None\n",
        "\n",
        "# Display the first few rows\n",
        "if df is not None:\n",
        "    df.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "Let's explore the dataset to understand what we're working with.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "if df is not None:\n",
        "    missing_values = df.isnull().sum()\n",
        "    missing_percent = (missing_values / len(df)) * 100\n",
        "    \n",
        "    missing_df = pd.DataFrame({\n",
        "        'Missing Values': missing_values,\n",
        "        'Percentage': missing_percent\n",
        "    })\n",
        "    \n",
        "    print(\"Missing values in each column:\")\n",
        "    display(missing_df[missing_df['Missing Values'] > 0].sort_values('Missing Values', ascending=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore book types\n",
        "if df is not None and 'type' in df.columns:\n",
        "    # Count book types\n",
        "    book_types = df['type'].dropna().str.split(', ').explode().value_counts()\n",
        "    \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x=book_types.values, y=book_types.index)\n",
        "    plt.title('Book Types Distribution')\n",
        "    plt.xlabel('Count')\n",
        "    plt.ylabel('Book Type')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Feature Engineering\n",
        "\n",
        "Now let's process the data and create features for our recommendation engine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process the data using our TextProcessor\n",
        "if df is not None:\n",
        "    processor = TextProcessor()\n",
        "    df_processed = processor.preprocess(df)\n",
        "    \n",
        "    print(f\"Processed data shape: {df_processed.shape}\")\n",
        "    print(f\"New columns added: {set(df_processed.columns) - set(df.columns)}\")\n",
        "    \n",
        "    # Display sample of processed data\n",
        "    df_processed[['ISBN', 'title', 'author_processed', 'type_processed', 'start_year', \n",
        "                 'decade', 'recency_score', 'popularity_score', 'corpus']].head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Train Recommendation Engine\n",
        "\n",
        "Now let's train our content-based recommendation engine using the processed data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train the recommender\n",
        "if df is not None and 'df_processed' in locals():\n",
        "    recommender = ContentBasedRecommender()\n",
        "    recommender.fit(df_processed)\n",
        "    \n",
        "    # Evaluate the model\n",
        "    evaluator = ModelEvaluator()\n",
        "    metrics = evaluator.evaluate(recommender, df_processed, test_size=0.2)\n",
        "    \n",
        "    # Display metrics\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Generate Recommendations\n",
        "\n",
        "Let's generate some recommendations for a sample book.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to display recommendations\n",
        "def display_recommendations(recommendations):\n",
        "    \"\"\"Display recommendations in a formatted way\"\"\"\n",
        "    for i, (_, book) in enumerate(recommendations.iterrows(), 1):\n",
        "        print(f\"{i}. {book['title']} (Similarity: {book['similarity_score']:.4f})\")\n",
        "        print(f\"   Author: {book.get('author', 'Unknown')}\")\n",
        "        print(f\"   Type: {book.get('type', 'Unknown')}\")\n",
        "        print(f\"   ISBN: {book.get('ISBN', 'Unknown')}\")\n",
        "        print()\n",
        "\n",
        "# Get recommendations for a sample book\n",
        "if df is not None and 'df_processed' in locals() and 'recommender' in locals():\n",
        "    # Find a book with a non-null title\n",
        "    sample_book = df_processed[df_processed['title'].notna()].iloc[0]\n",
        "    sample_title = sample_book['title']\n",
        "    \n",
        "    print(f\"Generating recommendations for: {sample_title}\")\n",
        "    recommendations = recommender.recommend(sample_title, n=5)\n",
        "    \n",
        "    display_recommendations(recommendations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try recommendations by ISBN\n",
        "if df is not None and 'df_processed' in locals() and 'recommender' in locals():\n",
        "    # Find a book with a non-null ISBN\n",
        "    sample_isbn = df_processed[df_processed['ISBN'].notna()].iloc[0]['ISBN']\n",
        "    \n",
        "    print(f\"Generating recommendations for ISBN: {sample_isbn}\")\n",
        "    try:\n",
        "        recommendations = recommender.get_recommendations_by_isbn(sample_isbn, n=5)\n",
        "        display_recommendations(recommendations)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we've demonstrated:\n",
        "\n",
        "1. Loading and exploring the book dataset\n",
        "2. Processing and preparing features for recommendation\n",
        "3. Training a content-based recommendation engine\n",
        "4. Generating recommendations based on book title and ISBN\n",
        "\n",
        "This recommendation engine can be used by teachers to find similar books to those they're already using in their curriculum.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
